{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de7c8c48-99be-41c9-92a0-69067f380b09",
   "metadata": {},
   "source": [
    "## DETECT OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49b803c-dace-4529-ac20-67264bff49c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inference_id': 'd96c5282-f7b7-4b4a-bf4d-46c2be85723d', 'time': 0.017839892000665714, 'image': {'width': 750, 'height': 1061}, 'predictions': [{'x': 378.5, 'y': 461.5, 'width': 665.0, 'height': 255.0, 'confidence': 0.9568327069282532, 'class': 'table', 'class_id': 1, 'detection_id': '0df36607-245c-4b5c-ac5d-dbf54c6d3525'}, {'x': 144.0, 'y': 72.0, 'width': 178.0, 'height': 64.0, 'confidence': 0.9423655867576599, 'class': 'paragraph', 'class_id': 0, 'detection_id': '3d65625b-152c-447f-bebe-9e3e831e98f7'}, {'x': 577.0, 'y': 255.0, 'width': 242.0, 'height': 110.0, 'confidence': 0.9342994689941406, 'class': 'paragraph', 'class_id': 0, 'detection_id': '37dd277a-f0a9-4dad-ac02-70ba1dd23940'}, {'x': 112.5, 'y': 155.5, 'width': 113.0, 'height': 63.0, 'confidence': 0.9314045906066895, 'class': 'paragraph', 'class_id': 0, 'detection_id': 'a4e29a0a-71bd-4ff1-bc67-b376cb055c12'}, {'x': 323.0, 'y': 247.0, 'width': 128.0, 'height': 90.0, 'confidence': 0.9209174513816833, 'class': 'paragraph', 'class_id': 0, 'detection_id': 'bd0ff91e-29b9-4bc5-80c5-636d9f0f1040'}, {'x': 653.0, 'y': 92.5, 'width': 94.0, 'height': 97.0, 'confidence': 0.9209113121032715, 'class': 'paragraph', 'class_id': 0, 'detection_id': '46be0a7f-fe23-4eb8-a271-66c627364d65'}, {'x': 482.0, 'y': 941.5, 'width': 196.0, 'height': 149.0, 'confidence': 0.8977222442626953, 'class': 'paragraph', 'class_id': 0, 'detection_id': '7a2fdf33-1deb-4ab1-9fd8-1583bf75c69c'}, {'x': 107.0, 'y': 247.5, 'width': 110.0, 'height': 89.0, 'confidence': 0.8792654275894165, 'class': 'paragraph', 'class_id': 0, 'detection_id': '49129a73-efaa-4737-ab9a-eae7f223c053'}, {'x': 617.5, 'y': 667.5, 'width': 177.0, 'height': 89.0, 'confidence': 0.805108368396759, 'class': 'paragraph', 'class_id': 0, 'detection_id': '50bcf8ae-cf67-4e95-992a-9af4e6e950a1'}]}\n"
     ]
    }
   ],
   "source": [
    "from inference_sdk import InferenceHTTPClient\n",
    "from PIL import Image, ImageDraw\n",
    "import pytesseract\n",
    "import re\n",
    "\n",
    "IMAGE_PATH = \"image2.png\"\n",
    "MODEL_ID = \"invoice-processing--githib/2\"\n",
    "API_KEY = \"I9NtOOtiqQm0MWTk2dvN\"\n",
    "API_URL = \"https://detect.roboflow.com\"\n",
    "\n",
    "CLIENT = InferenceHTTPClient(\n",
    "    api_url=API_URL,\n",
    "    api_key=API_KEY\n",
    ")\n",
    "\n",
    "response = CLIENT.infer(IMAGE_PATH, model_id=MODEL_ID)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a0414-15a6-4ecd-9f40-0a44c0ebe06f",
   "metadata": {},
   "source": [
    "## VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3018506a-3b3a-42af-a3ef-9e7da7fa26eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'x': 378.5,\n",
       "  'y': 461.5,\n",
       "  'width': 665.0,\n",
       "  'height': 255.0,\n",
       "  'confidence': 0.9568327069282532,\n",
       "  'class': 'table',\n",
       "  'class_id': 1,\n",
       "  'detection_id': '0df36607-245c-4b5c-ac5d-dbf54c6d3525'},\n",
       " {'x': 144.0,\n",
       "  'y': 72.0,\n",
       "  'width': 178.0,\n",
       "  'height': 64.0,\n",
       "  'confidence': 0.9423655867576599,\n",
       "  'class': 'paragraph',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '3d65625b-152c-447f-bebe-9e3e831e98f7'},\n",
       " {'x': 577.0,\n",
       "  'y': 255.0,\n",
       "  'width': 242.0,\n",
       "  'height': 110.0,\n",
       "  'confidence': 0.9342994689941406,\n",
       "  'class': 'paragraph',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '37dd277a-f0a9-4dad-ac02-70ba1dd23940'},\n",
       " {'x': 112.5,\n",
       "  'y': 155.5,\n",
       "  'width': 113.0,\n",
       "  'height': 63.0,\n",
       "  'confidence': 0.9314045906066895,\n",
       "  'class': 'paragraph',\n",
       "  'class_id': 0,\n",
       "  'detection_id': 'a4e29a0a-71bd-4ff1-bc67-b376cb055c12'},\n",
       " {'x': 323.0,\n",
       "  'y': 247.0,\n",
       "  'width': 128.0,\n",
       "  'height': 90.0,\n",
       "  'confidence': 0.9209174513816833,\n",
       "  'class': 'paragraph',\n",
       "  'class_id': 0,\n",
       "  'detection_id': 'bd0ff91e-29b9-4bc5-80c5-636d9f0f1040'},\n",
       " {'x': 653.0,\n",
       "  'y': 92.5,\n",
       "  'width': 94.0,\n",
       "  'height': 97.0,\n",
       "  'confidence': 0.9209113121032715,\n",
       "  'class': 'paragraph',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '46be0a7f-fe23-4eb8-a271-66c627364d65'},\n",
       " {'x': 482.0,\n",
       "  'y': 941.5,\n",
       "  'width': 196.0,\n",
       "  'height': 149.0,\n",
       "  'confidence': 0.8977222442626953,\n",
       "  'class': 'paragraph',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '7a2fdf33-1deb-4ab1-9fd8-1583bf75c69c'},\n",
       " {'x': 107.0,\n",
       "  'y': 247.5,\n",
       "  'width': 110.0,\n",
       "  'height': 89.0,\n",
       "  'confidence': 0.8792654275894165,\n",
       "  'class': 'paragraph',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '49129a73-efaa-4737-ab9a-eae7f223c053'},\n",
       " {'x': 617.5,\n",
       "  'y': 667.5,\n",
       "  'width': 177.0,\n",
       "  'height': 89.0,\n",
       "  'confidence': 0.805108368396759,\n",
       "  'class': 'paragraph',\n",
       "  'class_id': 0,\n",
       "  'detection_id': '50bcf8ae-cf67-4e95-992a-9af4e6e950a1'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"predictions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b75a78a5-d93f-45de-8efa-59e35dd20215",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unknown color specifier: 'light-green'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m\n\u001b[1;32m     23\u001b[0m     image\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     27\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(IMAGE_PATH)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mvisualize_image_with_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 19\u001b[0m, in \u001b[0;36mvisualize_image_with_boxes\u001b[0;34m(image, response)\u001b[0m\n\u001b[1;32m     15\u001b[0m     y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(y \u001b[38;5;241m+\u001b[39m height \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m height\u001b[38;5;241m*\u001b[39mpadding)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Draw the bounding box (rectangle) around the detected object\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# red if paragraph, yellow if table\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrectangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mred\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparagraph\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlight-green\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     draw\u001b[38;5;241m.\u001b[39mtext((x0, y0 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m), label, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m label\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparagraph\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myellow\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Show the image with bounding boxes\u001b[39;00m\n",
      "File \u001b[0;32m~/python_venv/ML/lib64/python3.12/site-packages/PIL/ImageDraw.py:409\u001b[0m, in \u001b[0;36mImageDraw.rectangle\u001b[0;34m(self, xy, fill, outline, width)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrectangle\u001b[39m(\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    403\u001b[0m     xy: Coords,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m     width: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    408\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Draw a rectangle.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 409\u001b[0m     ink, fill_ink \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getink\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fill_ink \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdraw\u001b[38;5;241m.\u001b[39mdraw_rectangle(xy, fill_ink, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/python_venv/ML/lib64/python3.12/site-packages/PIL/ImageDraw.py:161\u001b[0m, in \u001b[0;36mImageDraw._getink\u001b[0;34m(self, ink, fill)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ink \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ink, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 161\u001b[0m         ink \u001b[38;5;241m=\u001b[39m \u001b[43mImageColor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcolor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mink\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalette \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ink, numbers\u001b[38;5;241m.\u001b[39mNumber):\n\u001b[1;32m    163\u001b[0m         ink \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalette\u001b[38;5;241m.\u001b[39mgetcolor(ink, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image)\n",
      "File \u001b[0;32m~/python_venv/ML/lib64/python3.12/site-packages/PIL/ImageColor.py:144\u001b[0m, in \u001b[0;36mgetcolor\u001b[0;34m(color, mode)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;124;03mSame as :py:func:`~PIL.ImageColor.getrgb` for most modes. However, if\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m``mode`` is HSV, converts the RGB value to a HSV value, or if ``mode`` is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m:return: ``graylevel, (graylevel, alpha) or (red, green, blue[, alpha])``\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# same as getrgb, but converts the result to the given mode\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m rgb, alpha \u001b[38;5;241m=\u001b[39m \u001b[43mgetrgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m255\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rgb) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    146\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m rgb[\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[0;32m~/python_venv/ML/lib64/python3.12/site-packages/PIL/ImageColor.py:125\u001b[0m, in \u001b[0;36mgetrgb\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28mint\u001b[39m(m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m2\u001b[39m)), \u001b[38;5;28mint\u001b[39m(m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m3\u001b[39m)), \u001b[38;5;28mint\u001b[39m(m\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m    124\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown color specifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(color)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: unknown color specifier: 'light-green'"
     ]
    }
   ],
   "source": [
    "# Function to visualize the image with bounding boxes\n",
    "def visualize_image_with_boxes(image, response):\n",
    "    draw = ImageDraw.Draw(image)  # Create a drawing context\n",
    "\n",
    "    for prediction in response['predictions']:\n",
    "        x, y = prediction['x'], prediction['y']\n",
    "        width, height = prediction['width'], prediction['height']\n",
    "        label = prediction['class']\n",
    "\n",
    "        # Calculate bounding box coordinates\n",
    "        padding = 0.05    # adding padding since the ocr was missing a few characters sometimes so extending the dimensions of the box\n",
    "        x0 = int(x - width / 2 - width*padding)\n",
    "        y0 = int(y - height / 2 - height*padding)\n",
    "        x1 = int(x + width / 2 + width*padding)\n",
    "        y1 = int(y + height / 2 + height*padding)\n",
    "\n",
    "        # Draw the bounding box (rectangle) around the detected object\n",
    "        # red if paragraph, yellow if table\n",
    "        draw.rectangle([x0, y0, x1, y1], outline='red' if label==\"paragraph\" else \"light-green\", width=3)\n",
    "        draw.text((x0, y0 - 10), label, fill='red' if label==\"paragraph\" else \"yellow\")  \n",
    "\n",
    "    # Show the image with bounding boxes\n",
    "    image.show()\n",
    "\n",
    "\n",
    "\n",
    "image = Image.open(IMAGE_PATH)\n",
    "visualize_image_with_boxes(image, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eee0a9-6242-4af8-ab78-a5f0b607e7c2",
   "metadata": {},
   "source": [
    "## EXTRACT TEXTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a48ca9c2-8f01-4983-90fd-a9097f149db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: table, Bounding Box: (12, 321, 744, 601)\n",
      "Extracted Text:\n",
      "DESCRIPTION UNIT PRICE AMOUNT\n",
      "\n",
      "Frontend design restructure 9,999.00 9,999.00\n",
      "Custom icon package 975.00 41,950.00\n",
      "Gandhi mouse pad 99.00 297.00\n",
      "Subtotal 12,246.00\n",
      "\n",
      "GST 12.0% 1,469.52\n",
      "\n",
      "TOTAL 13,715.52\n",
      "--------------------------------------------------\n",
      "Class: paragraph, Bounding Box: (46, 36, 241, 107)\n",
      "Extracted Text:\n",
      "\n",
      "--------------------------------------------------\n",
      "Class: paragraph, Bounding Box: (443, 194, 710, 315)\n",
      "Extracted Text:\n",
      "INVOICE # 1N-001\n",
      "INVOICE DATE 29/01/2019\n",
      "\n",
      "POE 2430/2019\n",
      "DUE DATE 26/04/2019\n",
      "--------------------------------------------------\n",
      "Class: paragraph, Bounding Box: (50, 120, 174, 190)\n",
      "Extracted Text:\n",
      "\n",
      "--------------------------------------------------\n",
      "Class: paragraph, Bounding Box: (252, 197, 393, 296)\n",
      "Extracted Text:\n",
      "SHIPTO\n",
      "\n",
      "Kavindra Mannan\n",
      "\n",
      "264, Abdul Rehman\n",
      "Mumbai, Bihar 40009\n",
      "--------------------------------------------------\n",
      "Class: paragraph, Bounding Box: (601, 39, 704, 145)\n",
      "Extracted Text:\n",
      "\n",
      "--------------------------------------------------\n",
      "Class: paragraph, Bounding Box: (374, 859, 589, 1023)\n",
      "Extracted Text:\n",
      "TERMS & CONDITIONS\n",
      "\n",
      "Payment is due within 15 days.\n",
      "\n",
      "State Bank of India\n",
      "‘Account Number: 12345678\n",
      "Routing Number: 09876543210\n",
      "--------------------------------------------------\n",
      "Class: paragraph, Bounding Box: (46, 198, 167, 296)\n",
      "Extracted Text:\n",
      "BILLTO\n",
      "\n",
      "Kavindra Mannan\n",
      "\n",
      "27, Dif City, Gupta\n",
      "Delhi, Dethi 40003\n",
      "--------------------------------------------------\n",
      "Class: paragraph, Bounding Box: (520, 618, 714, 716)\n",
      "Extracted Text:\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define regex patterns for specific fields\n",
    "patterns = {\n",
    "    'invoice_number': r\"Invoice No[: ]?\\s*([A-Za-z0-9\\-]+)\",\n",
    "    'gstin': r\"GSTIN[: ]?\\s*([0-9A-Z]{15})\",\n",
    "    'date': r\"Date[: ]?\\s*([\\d]{2}/[\\d]{2}/[\\d]{4})\",  # Match date format DD/MM/YYYY\n",
    "    'amount': r\"Total[: ]?\\s*([₹$]?\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)\"  # Match amounts like ₹15,345.00 or $1,000.00\n",
    "}\n",
    "\n",
    "# List to store all extracted data\n",
    "extracted_data = {}\n",
    "\n",
    "# Function to perform OCR and extract specific fields using regex\n",
    "def extract_data_with_regex(response, patterns, image):\n",
    "    texts = []  # List to store extracted texts\n",
    "    for prediction in response['predictions']:\n",
    "        x, y = prediction['x'], prediction['y']\n",
    "        width, height = prediction['width'], prediction['height']\n",
    "        label = prediction['class']\n",
    "\n",
    "        # Calculate bounding box coordinates\n",
    "        padding = 0.05    # adding padding since the ocr was missing a few characters sometimes so extending the dimensions of the box\n",
    "        x0 = int(x - width / 2 - width*padding)\n",
    "        y0 = int(y - height / 2 - height*padding)\n",
    "        x1 = int(x + width / 2 + width*padding)\n",
    "        y1 = int(y + height / 2 + height*padding)\n",
    "\n",
    "        # Crop the region of interest (ROI)\n",
    "        roi = image.crop((x0, y0, x1, y1))\n",
    "\n",
    "        # Perform OCR on the cropped region\n",
    "        extracted_text = pytesseract.image_to_string(roi, lang='eng')  # Change 'eng' if using other languages\n",
    "        texts.append({'class': label, 'bounding_box': (x0, y0, x1, y1), 'text': extracted_text.strip()})\n",
    "\n",
    "        # Extract specific data using regex patterns\n",
    "        for key, pattern in patterns.items():\n",
    "            match = re.search(pattern, extracted_text)\n",
    "            if match:\n",
    "                extracted_data[key] = match.group(1)\n",
    "                # Print extracted data here\n",
    "                print(f\"{key}: {match.group(1)}\")\n",
    "\n",
    "    return texts\n",
    "\n",
    "\n",
    "texts = extract_data_with_regex(response, patterns, image)\n",
    "for text in texts:\n",
    "    print(f\"Class: {text['class']}, Bounding Box: {text['bounding_box']}\")\n",
    "    print(f\"Extracted Text:\\n{text['text']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b671a-53ec-4b0d-9b92-9a8a8de0388c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
